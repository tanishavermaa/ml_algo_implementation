{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
    "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
    "probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "\n",
    "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "\n",
    "Q3. How does Bernoulli Naive Bayes handle missing values?\n",
    "\n",
    "Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "\n",
    "Q5. What is Bayes' theorem?\n",
    "\n",
    "Q6. What is the formula for Bayes' theorem?\n",
    "\n",
    "Q7. How is Bayes' theorem used in practice?\n",
    "\n",
    "Q8. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Q9. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "To find the probability that an employee is a smoker given that they use the health insurance plan, you can use Bayes' theorem. Let A be the event that an employee is a smoker, and B be the event that an employee uses the health insurance plan.\n",
    "\n",
    "Bayes' theorem states:\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "In this case:\n",
    "\n",
    "P(A) is the probability that an employee is a smoker, which is 40% or 0.4.\n",
    "P(B|A) is the probability that an employee uses the health insurance plan given that they are a smoker. This information is not provided, so we need additional data to calculate it.\n",
    "P(B) is the probability that an employee uses the health insurance plan, which is 70% or 0.7.\n",
    "Without information on P(B|A), you cannot calculate the probability that an employee is a smoker given that they use the health insurance plan.\n",
    "\n",
    "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "Bernoulli Naive Bayes and Multinomial Naive Bayes are both variants of the Naive Bayes algorithm used for text classification or other categorization tasks, but they handle data differently:\n",
    "\n",
    "Bernoulli Naive Bayes:\n",
    "\n",
    "Suitable for binary feature data (0s and 1s), often used for text classification.\n",
    "Assumes that features are binary variables, indicating the presence or absence of words or features in the document.\n",
    "Ignores the frequency or count of terms; it's concerned with whether a term appears or not.\n",
    "Multinomial Naive Bayes:\n",
    "\n",
    "Suitable for text data where features represent word frequencies or counts.\n",
    "Considers the frequency of words in documents, not just their presence or absence.\n",
    "Often used in text classification tasks like spam detection or topic classification.\n",
    "Q3. How does Bernoulli Naive Bayes handle missing values?\n",
    "Bernoulli Naive Bayes assumes that features are binary (0 or 1), indicating the presence or absence of features in the data. If you encounter missing values in your dataset, you should decide how to handle them before applying Bernoulli Naive Bayes.\n",
    "\n",
    "Common approaches for handling missing values include:\n",
    "\n",
    "Imputing missing values: You can replace missing values with zeros or ones, depending on the context and the nature of your data.\n",
    "Removing instances: If the number of instances with missing values is small, you may consider removing those instances from your dataset.\n",
    "Encoding missing values: You can also introduce an additional binary feature that explicitly represents the presence or absence of a feature, including missing values.\n",
    "Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "Yes, Gaussian Naive Bayes can be used for multi-class classification. It's a variant of the Naive Bayes algorithm that works well with continuous data, and it can handle multiple classes. Gaussian Naive Bayes assumes that the features follow a Gaussian (normal) distribution, and it estimates the mean and variance for each class to make predictions. It's commonly used for tasks where the features are continuous variables, such as in medical diagnosis or data clustering.\n",
    "\n",
    "Q5. What is Bayes' theorem?\n",
    "Bayes' theorem is a fundamental concept in probability theory and statistics that describes how to update the probability of an event based on new evidence. It provides a formal way to calculate conditional probabilities.\n",
    "\n",
    "Q6. What is the formula for Bayes' theorem?\n",
    "Bayes' theorem is expressed mathematically as:\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A|B) is the probability of event A occurring given that event B has occurred.\n",
    "P(B|A) is the probability of event B occurring given that event A has occurred.\n",
    "P(A) is the prior probability of event A.\n",
    "P(B) is the prior probability of event B.\n",
    "Q7. How is Bayes' theorem used in practice?\n",
    "Bayes' theorem is used in various fields, including:\n",
    "\n",
    "Spam email filtering.\n",
    "Medical diagnosis.\n",
    "Machine learning algorithms like Naive Bayes for text classification.\n",
    "Bayesian inference for statistical modeling and data analysis.\n",
    "Bayesian networks for probabilistic reasoning in artificial intelligence.\n",
    "It helps in updating beliefs and making predictions based on observed data or evidence.\n",
    "\n",
    "Q8. What is the relationship between Bayes' theorem and conditional probability?\n",
    "Bayes' theorem is a formal representation of conditional probability. It describes how to calculate the probability of an event A given that event B has occurred. In other words, it provides a way to update our beliefs (conditional probability) based on new evidence. Bayes' theorem is a fundamental tool for probabilistic reasoning and inference.\n",
    "\n",
    "Q9. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "The choice of which type of Naive Bayes classifier to use depends on the nature of your data and the problem you are trying to solve:\n",
    "\n",
    "Use Bernoulli Naive Bayes when dealing with binary data, such as text classification where you're interested in the presence or absence of words or features.\n",
    "Use Multinomial Naive Bayes for text classification with term frequencies or count-based data, like word counts in documents.\n",
    "Use Gaussian Naive Bayes for continuous data, where features are assumed to follow a Gaussian distribution.\n",
    "Your choice should be guided by the characteristics of your dataset and the assumptions that best align with your problem domain. It's often a good practice to try different Naive Bayes variants and select the one that provides the best performance through cross-validation or other evaluation methods.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "User\n",
    "\n",
    "2 / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "X_y=load_npz(\"class_X_y.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_y[:,:-1]\n",
    "y=X_y[:,-1]\n",
    "X=X.toarray()\n",
    "y=y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinb=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\eda_fe_regress&class\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=multinb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1024\n",
      "           1       0.97      0.79      0.87       161\n",
      "\n",
      "    accuracy                           0.97      1185\n",
      "   macro avg       0.97      0.89      0.93      1185\n",
      "weighted avg       0.97      0.97      0.97      1185\n",
      "\n",
      "[[1020    4]\n",
      " [  34  127]]\n",
      "0.9679324894514768\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
